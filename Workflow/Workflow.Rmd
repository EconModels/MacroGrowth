---
title: "Workflow"
author: "Matthew Kuperus Heun"
date: "29 July 2014"
output: html_document
---

This file contains information about the workflow for analyses.

### Add new data
* Add a file that contains the historical data from `<Source>` (name should be `<Source>.txt`) 
in the `data` directory at the top level of the repository.   
* Add any Excel workbooks or other metadata in `data/Excel Workbooks/<Source>`.

### Create historical data frame
* Run `Scripts/PreProcess.R -S <Source>` to create the historical data frame for `<Source>`.
The file will be stored at `Packages/EconData/data/<Source>.rda`.
This command is fast; it can be run on a laptop.    
* Build and reload the `EconData` package on a local machine.    
* Push the changes to GitHub.   
* On acc, Pull from GitHub.     
* Install the `EconData` package from GitHub to dahl
    + `ssh` to node-00 on dahl.   
    + Open an R shell by saying `R` at the command prompt.    
    + Say `require(devtools)`.
    + Say `install_github("MatthewHeun/Econ-Growth-R-Analysis/Packages/EconData")`.      

This makes the historical data available to the nodes of dahl.
This command doesn't work from fs1 or any of the other nodes of dahl (node-01 through node-42).

### Create the batch script
* Create the file `Scripts/<Source>_batch.bash` file.
    + It is probably best to modify an existing `<Source>_batch.bash` file.      
    + Be sure to edit the `OUTDIR` variable to be `OUTDIR="$LOC_PATH/data_resample/<Source>"`.
    + Change the final line (the one that runs the `OrigModels.R script`) to be `ssh node-xx "cd $LOC_PATH; Scripts/OrigModels.R -S <Source> &> $OUTDIR/node-xx.txt" &`.   
    + Distribute the work over the nodes in a way that makes sense.
* Push the `<Source>_batch.bash` file to GitHub.
* On acc, Pull from GitHub.      

### Submit the job to dahl
* `cd` to the `Econ-Growth-R-Analysis` directory from fs1.calvin.edu.
* Run `Scripts/<Source>_batch.bash "-n 2 -C"` to test that things work as expected.
* Then do `Scripts/<Source>_batch.bash "-n 1000 -C"` to do a complete run.
* Check dahl's status at (http://fs1.calvin.edu/ganglia/?m=load_one&r=hour&s=by%2520name&c=dahl&h=&sh=1&hc=4&z=small).
* Check progress with `more data_resample/<Source>/node-*.txt`.

### Post-process the results
* Run `Scripts/PostProcess.R -R data_resample/<Source>` on a node of dahl to create:       
    + `Packages/EconData/data/<Source>_Coeffs.rda` and
    + `Packages/EconData/data/<Source>_Fitted.rda`.         

Note that this command will need to be issued from a node of the cluster (e.g., node-00), not from `fs1.calvin.edu`.
`fs1` does not have a full install of R.

### Download post-processed results to local machine
* From a local computer, say `Scripts/DownloadResults.R -u <user> -S <Source> -d`, where `<user>` is 
a username on dahl, `<Source>` is the data source of interest, and `-d` will 
print the files to be transferred to the local machine, rather than transfer them.
* Verify that the list of files to be transferred looks right.
* From a local computer, say `Scripts/DownloadResults.R -u <user> -S <Source>` to download the files.

### Add processed results to the EconData package
* On the local machine, build and reload the `EconData` package.

At this point, all new results should be available in the `EconData` package on the local machine.
Objects will be named:

* `<Source>_Coeffs` (from the file `Packages/EconData/data/<Source>_Coeffs.rda`)  
* `<Source>_Fitted` (from the file `Packages/EconData/data/<Source>_Fitted.rda`)  
* `<Source>_Models` (from the file `Packages/EconData/data/<Source>_OrigModels.rda`)  